{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS 229 - Bayes",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaEMUd4nSBYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Cloud things\n",
        "\n",
        "project_id = 'cs229-project-258114'\n",
        "bucket_name = 'goodreads_reviews'\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "# Download the file from a given Google Cloud Storage bucket.\n",
        "!gsutil cp gs://{bucket_name}/finalbooks.csv /tmp/finalbooks.csv\n",
        "!gsutil cp gs://{bucket_name}/finalratings.csv /tmp/ratings.csv \n",
        "!gsutil cp gs://{bucket_name}/train.csv /tmp/train.csv \n",
        "!gsutil cp gs://{bucket_name}/test.csv /tmp/test.csv \n",
        "#!gsutil cp gs://{bucket_name}/Bayes.csv /tmp/Bayes.csv \n",
        "## !gsutil cp gs://{bucket_name}/Popularity/goodreads-best-books.zip /tmp/best.zip\n",
        "\n",
        "# basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# tools\n",
        "import scipy\n",
        "import math\n",
        "import random\n",
        "import sklearn\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "finalbooks = pd.read_csv('../tmp/finalbooks.csv')\n",
        "ratings = pd.read_csv('../tmp/ratings.csv')\n",
        "train = pd.read_csv('../tmp/train.csv')\n",
        "test = pd.read_csv('../tmp/test.csv')\n",
        "#bayes = pd.read_csv('../tmp/Bayes.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Eid_fYsSSUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## NDGC & RMSE\n",
        "\n",
        "def dcg_k(r, k):\n",
        "    \"\"\" Discounted Cumulative Gain (DGC)  \n",
        "    Args:\n",
        "        r: True Ratings in Predicted Rank Order (1st element is top recommendation)\n",
        "        k: Number of results to consider\n",
        "    Returns:\n",
        "        DCG\n",
        "    \"\"\"\n",
        "  \n",
        "    r = np.asfarray(r)[:k]\n",
        "    return np.sum(2**r / np.log2(np.arange(2, r.size + 2)))      \n",
        "\n",
        "\n",
        "\n",
        "def ndcg_k(r, k):\n",
        "    \"\"\"Normalized Discounted Cumulative Gain (NDCG)\n",
        "    Args:\n",
        "        r: True Ratings in Predicted Rank Order (1st element is top recommendation)\n",
        "        k: Number of results to consider\n",
        "    Returns:\n",
        "        NDCG\n",
        "    \"\"\"\n",
        "    dcg_max = dcg_k(sorted(r, reverse=True), k)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    return dcg_k(r, k) / dcg_max\n",
        "\n",
        "def mean_ndcg(rs):\n",
        "    \"\"\"Mean NDCG for all users\n",
        "    Args:\n",
        "        rs: Iterator / For each user: True Ratings in Predicted Rank Order\n",
        "    Returns:\n",
        "        Mean NDCG\n",
        "    \"\"\"\n",
        "    return np.mean([ndcg_k(r, len(r)) for r in rs])\n",
        "\n",
        "def rmse(y,h):\n",
        "    \"\"\"RMSE\n",
        "    Args:\n",
        "        y: real y\n",
        "        h: predicted y\n",
        "    Returns:\n",
        "        RMSE\n",
        "    \"\"\"\n",
        "    a = y-h\n",
        "\n",
        "    return np.sqrt(sum(a**2)/len(a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0cPT69SZgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## DEFINING THE TAIL\n",
        "tailcomp = ratings.groupby(by= 'newbookid', as_index=False).agg({'rating':pd.Series.count}).sort_values(by = 'rating', ascending = False)\n",
        "tot = sum(tailcomp['rating'])\n",
        "tailcomp['popshare']= [x/tot for x in tailcomp['rating']]\n",
        "tailcomp['popshare']= tailcomp['popshare'].cumsum()\n",
        "tailcomp['category']= ['Head' if x<0.95 else \"Tail\" for x in tailcomp['popshare']]\n",
        "\n",
        "tail = tailcomp.loc[tailcomp.popshare >= 0.95]\n",
        "tail"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBEddNjdSkkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_words(message):\n",
        "    \"\"\"Get the normalized list of words from a message string.\n",
        "\n",
        "    This function should split a message into words, normalize them, and return\n",
        "    the resulting list. For splitting, you should split on spaces. For normalization,\n",
        "    you should convert everything to lowercase.\n",
        "\n",
        "    Args:\n",
        "        message: A string containing an SMS message\n",
        "\n",
        "    Returns:\n",
        "       The list of normalized words from the message.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    words = message\n",
        "    words = words.split(\" \")\n",
        "    words = [x.lower() for x in words]\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "\n",
        "def create_dictionary(messages):\n",
        "    \"\"\"Create a dictionary mapping words to integer indices.\n",
        "\n",
        "    Args:\n",
        "        messages: A list of strings containing SMS messages\n",
        "\n",
        "    Returns:\n",
        "        A python dict mapping words to integers.\n",
        "    \"\"\"\n",
        "\n",
        "    word_counts = collections.defaultdict(int)\n",
        "\n",
        "    for message in messages:\n",
        "        for word in set(get_words(message)):\n",
        "            word_counts[word] += 1\n",
        "\n",
        "    resulting_dictionary = {}\n",
        "\n",
        "    for word, count in word_counts.items():\n",
        "        if count >= 25 and word not in stopwords.words('english') and len(word) > 1:\n",
        "            next_index = len(resulting_dictionary)\n",
        "            resulting_dictionary[word] = next_index\n",
        "\n",
        "    return resulting_dictionary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transform_text(messages, word_dictionary):\n",
        "    \"\"\"Transform a list of text messages into a numpy array for further processing.\n",
        "\n",
        "    Args:\n",
        "        messages: A list of strings where each string is an SMS message.\n",
        "        word_dictionary: A python dict mapping words to integers.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array marking the words present in each message.\n",
        "        Where the component (i,j) is the number of occurrences of the\n",
        "        j-th vocabulary word in the i-th message.\n",
        "    \"\"\"\n",
        "\n",
        "    A = np.zeros((len(messages), len(word_dictionary)))\n",
        "\n",
        "    for i, message in enumerate(messages):\n",
        "        for word in get_words(message):\n",
        "            if word in word_dictionary:\n",
        "                A[i, word_dictionary[word]] += 1\n",
        "\n",
        "    return A\n",
        "\n",
        "\n",
        "\n",
        "def fit_naive_bayes_model(matrix, labels):\n",
        "    \"\"\"Fit a naive bayes model.\n",
        "\n",
        "    Args:\n",
        "        matrix: A numpy array containing word counts for the training data\n",
        "        labels: The binary (0 or 1) labels for that training data\n",
        "\n",
        "    Returns: The trained model\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    model = {}\n",
        "\n",
        "    phi = (1. * sum(labels) / len(labels))*0.95+0.05*0.5\n",
        "    model['logphi_0'] = np.log(1.-phi)\n",
        "    model['logphi_1'] = np.log(phi)\n",
        "    theta_0 = (matrix[labels == 0]).sum(axis=0) + 1\n",
        "    theta_1 = (matrix[labels == 1]).sum(axis=0) + 1\n",
        "    theta_0 /= theta_0.sum()\n",
        "    theta_1 /= theta_1.sum()\n",
        "    model['logtheta_0'] = np.log(theta_0)\n",
        "    model['logtheta_1'] = np.log(theta_1)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def predict_from_naive_bayes_model(model, matrix):\n",
        "    \"\"\"Use a Naive Bayes model to compute predictions for a target matrix.\n",
        "\n",
        "    Args:\n",
        "        model: A trained model from fit_naive_bayes_model\n",
        "        matrix: A numpy array containing word counts\n",
        "\n",
        "    Returns: A numpy array containg the predictions from the model\n",
        "    \"\"\"\n",
        " \n",
        "    output = np.zeros(matrix.shape[0])\n",
        "\n",
        "    logphi_0 = model['logphi_0']\n",
        "    logphi_1 = model['logphi_1']\n",
        "    logtheta_0 = model['logtheta_0']\n",
        "    logtheta_1 = model['logtheta_1']\n",
        "    logprobs_0 = (matrix * logtheta_0).sum(axis=1) + logphi_0\n",
        "    logprobs_1 = (matrix * logtheta_1).sum(axis=1) + logphi_1\n",
        "\n",
        "    output = (logprobs_1/(logprobs_1+logprobs_0))\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "def get_top_five_naive_bayes_words(model, dictionary):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        model: The Naive Bayes model returned from fit_naive_bayes_model\n",
        "        dictionary: A mapping of word to integer ids\n",
        "\n",
        "    Returns: A list of the top five most indicative words in sorted order with the most indicative first\n",
        "    \"\"\"\n",
        "\n",
        "    ids = np.argsort(model['logtheta_0'] - model['logtheta_1'])[:5]\n",
        "\n",
        "    reverse_dictionary = {i: word for word, i in dictionary.items()}\n",
        "\n",
        "    return [reverse_dictionary[i] for i in ids]\n",
        "  \n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtMtsa1S42wS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "finalbooks['snippet'] = finalbooks['snippet'].fillna(finalbooks['title'])\n",
        "finalbooks['snippet'] = finalbooks['snippet'].str.replace(r'[^\\w\\s]',\"\")\n",
        "finalbooks['snippet'] = finalbooks['snippet'].fillna(finalbooks['tag_cloud'])\n",
        "#finalbooks['tag_cloud'] = finalbooks['tag_cloud'].str.replace('-',\" \")\n",
        "#finalbooks['words'] = finalbooks['snippet'] +\" \"+finalbooks['tag_cloud']+\" \"+finalbooks['first_author']\n",
        "dico = create_dictionary(finalbooks['snippet'])\n",
        "dico"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcMaGo_nSi4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(dico)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGs3LWQH428r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = transform_text(finalbooks['snippet'], dico)\n",
        "finalbooks['binary']= [1 if x >=4 else 0 for x in finalbooks['average_rating']]\n",
        "ratings['binary']= [1 if x >=4 else 0 for x in ratings['rating']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlfAnw-M43HW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allpreds = []\n",
        "topwords = []\n",
        "indicators = np.zeros(len(dico))\n",
        "for i in range(15000):\n",
        "    User = train.loc[train.newuser_id == i+1].sort_values('newbookid')\n",
        "    User['binary']= [1 if x >=4 else 0 for x in User['rating']]\n",
        "    A[User['newbookid']-1,:] \n",
        "    model = fit_naive_bayes_model(A[User['newbookid']-1,:], User['binary'])\n",
        "    result = predict_from_naive_bayes_model(model, A)\n",
        "    UserRes = finalbooks.filter(['newbookid'])\n",
        "    UserRes['newuser_id'] = i+1 \n",
        "    UserRes['pred'] = result\n",
        "    allpreds.append(UserRes)\n",
        "    #top5 = get_top_five_naive_bayes_words(model, dico)\n",
        "    #topwords.append(top5)\n",
        "    indicators = indicators + (model['logtheta_0'] - model['logtheta_1'])\n",
        "    if (i+1)%1000 == 0: print(\"done: \", i+1)\n",
        "## Append in a list and then use concat\n",
        "## get_top_five_naive_bayes_words(model, dico)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Y8vWwUjyaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indicators = indicators*15000\n",
        "ids = np.argsort(-indicators)[:5]\n",
        "reverse_dictionary = {i: word for word, i in dico.items()}\n",
        "[reverse_dictionary[i] for i in ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L36xI_jylgyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.sort(indicators*1000000000000)[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vncNq2Eq43Pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fivewords = np.concatenate(topwords, axis=0 )\n",
        "from collections import Counter\n",
        "for key, value in sorted(Counter(fivewords).items(), reverse=True, key=lambda item: item[1]):\n",
        "    print(\"%s: %s\" % (key, value))\n",
        "\n",
        "\n",
        "#Bayes =pd.DataFrame(predictions, columns=['newbookid', 'newuser_id', 'pred']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CplV6-hqH_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.concatenate(allpreds, axis=0 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm5qHRTSqbg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bayes =pd.DataFrame(predictions, columns=['newbookid','newuser_id', 'pred']) \n",
        "bayes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1NjMmSCSk99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bayesrank = test.merge(bayes,on = ['newbookid', 'newuser_id'])\n",
        "bayesrank = bayesrank.sort_values(by=['newuser_id', 'pred'], ascending=False)\n",
        "bayesrank.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0GmnLQqSlBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bayesrank['pred']=bayesrank['pred']*4+1\n",
        "bayesrank.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCOgdfDurI5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bayesrank['pred'].min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm17ziRiSk7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['conc']=train['newuser_id'].map(str)+train['newbookid'].map(str)\n",
        "bayes['conc']=bayes['newuser_id'].map(str)+bayes['newbookid'].map(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tF1HE3VEPjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bayesfin = bayes[~bayes.conc.isin(train.conc)]\n",
        "bayesfin.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lXwHFLcWvOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bayeslist = []\n",
        "for i in range(15000):\n",
        "    a = bayesrank.loc[bayesrank.newuser_id == i+1]['rating'].tolist()\n",
        "    bayeslist.append(a)\n",
        "    if (i+1)%1000 == 0: print(\"done: \", i+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to3brz1NWq16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = np.array([ndcg_k(r, len(r)) for r in bayeslist])\n",
        "\n",
        "facet, axes = plt.subplots(1, 1, figsize=(10, 3))\n",
        "n, bins, patches = plt.hist(b, 200, facecolor='blue', alpha=0.5) #, log = True)   \n",
        "plt.title('Distribution of NDGC among Users for the Bayes model')\n",
        "plt.show()\n",
        "\n",
        "# [ndcg_k(r, len(r)) for r in poplista]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5PPCmZRm33H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = b[b == 1]\n",
        "sum(d)/15000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c4dC10AWpbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#top10 = bayesfin.sort_values('pred',ascending = False).groupby('newuser_id').head(10)\n",
        "#top50 = bayesfin.sort_values('pred',ascending = False).groupby('newuser_id').head(50)\n",
        "\n",
        "print('(1) Bayes Model RMSE: ', np.round(rmse(bayesrank['pred'],bayesrank['rating']), decimals=3))\n",
        "print('(2) Bayes Model NDCG: ', np.round(mean_ndcg(bayeslist), decimals=3))\n",
        "print(\"(2) Median NDCG: \", np.round(np.median(b), decimals=3))\n",
        "print(\"(2) Share of NDCG =1 among Users: \", np.round(sum(d)/15000, decimals=3))\n",
        "#print('(3) Bayes Model Div10 Score: ',np.round(sum(np.in1d(top10.newbookid, tail.newbookid))/len(top10), decimals=3))\n",
        "#print('(3) Bayes Model Div50 Score: ',np.round(sum(np.in1d(top50.newbookid, tail.newbookid))/len(top50), decimals=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jee7hVycrtFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bayesranktrain = train.merge(bayes,on = ['newbookid', 'newuser_id'])\n",
        "bayesranktrain = bayesranktrain.sort_values(by=['newuser_id', 'pred'], ascending=False)\n",
        "bayesranktrain['pred']=bayesranktrain['pred']*4+1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJeV3QEIr2Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bayeslisttrain = []\n",
        "for i in range(15000):\n",
        "    a = bayesranktrain.loc[bayesranktrain.newuser_id == i+1]['rating'].tolist()\n",
        "    bayeslisttrain.append(a)\n",
        "    if (i+1)%1000 == 0: print(\"done: \", i+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVKiH5N6Sk4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# print('Popularity Model MAP: ', mean_average_precision(poplistb))\n",
        "print('(1) Bayes Model Train RMSE: ', np.round(rmse(bayesranktrain['pred'],bayesranktrain['rating']), decimals=3))\n",
        "print('(2) Bayes Model Train NDCG: ', np.round(mean_ndcg(bayeslisttrain), decimals=3))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
